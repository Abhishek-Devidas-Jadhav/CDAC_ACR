{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "211aecbe-789c-4cd7-a385-a682c0b0f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install util\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38cabda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 22:01:40.528561: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "### Import Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "import struct\n",
    "#import yolov3_util\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from yolov3_util import decode_netout, WeightReader, correct_yolo_boxes, do_nms, make_yolov3_model\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import add, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea1cebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic parameters\n",
    "\n",
    "inpDir = '../input' # location where input data is stored\n",
    "outDir = '../output' # location to store outputs\n",
    "mdlDir = './model_yolo' # location to store outputs\n",
    "imgDir = 'images'\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "EPOCHS = 100 # number of cycles to run\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (15,15),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large'\n",
    "         }\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c59117",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The most salient feature of v3 is that it makes detections at three different scales.\n",
    "### [Bounding box](http://christopher5106.github.io/object/detectors/2017/08/10/bounding-box-object-detectors-understanding-yolo.html)\n",
    "YOLO v3 predicts boxes at 3 different scales. For the same image of 416 x 416, the number of predicted boxes are 10,647."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99886e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the labels\n",
    "'''labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "'''\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"pottedplant\"]\n",
    "\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416\n",
    "\n",
    "# Anchor Size\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.5 #0.7 # 0.3\n",
    "\n",
    "nonmaxsup_threshold= 0.45 #0.45 #0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "273acfdd-7ae3-4338-9f28-38a5da4d6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\n",
    "    # Layer 16 => 36\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "        \n",
    "    skip_36 = x\n",
    "        \n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "        \n",
    "    skip_61 = x\n",
    "        \n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "        \n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740596-f85d-419b-ba16-603ada0690bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a74d53b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_conv_block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mmake_yolov3_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# define the model\u001b[39;00m\n\u001b[32m      3\u001b[39m weight_reader = WeightReader(os.path.join(mdlDir, \u001b[33m'\u001b[39m\u001b[33myolov3.weights\u001b[39m\u001b[33m'\u001b[39m)) \u001b[38;5;66;03m# load the model weights\u001b[39;00m\n\u001b[32m      5\u001b[39m weight_reader.load_weights(model) \u001b[38;5;66;03m# set the model weights into the model\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mmake_yolov3_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m input_image = Input(shape=(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m3\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Layer  0 => 4\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m x = \u001b[43m_conv_block\u001b[49m(input_image, [{\u001b[33m'\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m32\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbnorm\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mleaky\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mlayer_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m},\n\u001b[32m      6\u001b[39m                               {\u001b[33m'\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m64\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbnorm\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mleaky\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mlayer_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m},\n\u001b[32m      7\u001b[39m                               {\u001b[33m'\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m32\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbnorm\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mleaky\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mlayer_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m},\n\u001b[32m      8\u001b[39m                               {\u001b[33m'\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m64\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbnorm\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mleaky\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mlayer_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m}])\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Layer  5 => 8\u001b[39;00m\n\u001b[32m     11\u001b[39m x = _conv_block(x, [{\u001b[33m'\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m128\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbnorm\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mleaky\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mlayer_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m5\u001b[39m},\n\u001b[32m     12\u001b[39m                     {\u001b[33m'\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m'\u001b[39m:  \u001b[32m64\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbnorm\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mleaky\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mlayer_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m6\u001b[39m},\n\u001b[32m     13\u001b[39m                     {\u001b[33m'\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m128\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbnorm\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mleaky\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mlayer_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m7\u001b[39m}])\n",
      "\u001b[31mNameError\u001b[39m: name '_conv_block' is not defined"
     ]
    }
   ],
   "source": [
    "model = make_yolov3_model() # define the model\n",
    "\n",
    "weight_reader = WeightReader(os.path.join(mdlDir, 'yolov3.weights')) # load the model weights\n",
    "\n",
    "weight_reader.load_weights(model) # set the model weights into the model\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']) # Compile the model\n",
    "\n",
    "# save the model to file\n",
    "model.save(os.path.join(mdlDir, 'yolo3_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d4da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455d9878",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load yolov3 model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#model = tf.keras.models.load_model(os.path.join(mdlDir, 'yolo3_model.h5'))\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mload_model\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m./model_yolo/yolo3_model.h5\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# load yolov3 model\n",
    "#model = tf.keras.models.load_model(os.path.join(mdlDir, 'yolo3_model.h5'))\n",
    "model = load_model('./model_yolo/yolo3_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0eef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "    \n",
    "    # load the image to get its shape\n",
    "    image = tf.keras.preprocessing.image.load_img(filename)\n",
    "    width, height = image.size\n",
    "    \n",
    "    # load the image with the required size (Should not we be better off loading once????)\n",
    "    image = tf.keras.preprocessing.image.load_img(filename, target_size=shape)\n",
    "    \n",
    "    # convert to a 3D Numpy array. \n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    \n",
    "    # scale values to between 0 and 1\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    \n",
    "    #print ('before expand', image.shape, 'max pixel value', image.max())\n",
    "    \n",
    "    # add a dimension so that we have one sample\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    #print ('after expand', image.shape)\n",
    "    \n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14465dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    \n",
    "    # iterate all boxes\n",
    "    for box in boxes:\n",
    "        \n",
    "        # iteratare all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            \n",
    "            # check if the threshold for this label is high enough to be listed\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100) # don't break, many labels may trigger for one box\n",
    "                \n",
    "    return v_boxes, v_labels, v_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "    \n",
    "    # load the image\n",
    "    data = plt.imread(filename)\n",
    "    \n",
    "    # plot the image\n",
    "    plt.imshow(data)\n",
    "    \n",
    "    # get the context for drawing boxes\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"{:s} ({:.0f}%)\".format(v_labels[i], v_scores[i])\n",
    "        plt.text(x1, y1, label, color='white')\n",
    "        img_name = filename.split('/')[-1]      \n",
    "        plt.savefig(os.path.join(outDir, img_name))\n",
    "    \n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceff3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = os.path.join(inpDir, imgDir, 'predict')\n",
    "    \n",
    "imgList = [f for f in os.listdir(test_data_dir) if os.path.isfile(os.path.join(test_data_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our new photo\n",
    "photo_filename = os.path.join(test_data_dir, imgList[2])\n",
    "\n",
    "\n",
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "\n",
    "# make prediction\n",
    "y_pred = model.predict(image)\n",
    "\n",
    "# summarize the shape of the list of arrays\n",
    "print([a.shape for a in y_pred])\n",
    "\n",
    "boxes = list()\n",
    "for i in range(len(y_pred)):\n",
    "    # decode the output of the network\n",
    "    boxes += decode_netout(y_pred[i][0], anchors[i], class_threshold, nonmaxsup_threshold, input_h, input_w)\n",
    "\n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "\n",
    "# suppress non-maximal boxes\n",
    "do_nms(boxes, 0.5)\n",
    "\n",
    "# get the details of the detected objects\n",
    "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "\n",
    "# What did you find in the picture\n",
    "for i in range(len(v_boxes)):\n",
    "    print(v_labels[i], v_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048bd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d488cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
